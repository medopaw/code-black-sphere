# 在线判题工具 - 开发计划文档

本文档根据《技术设计文档：在线判题工具》(DESIGN.MD) 制定，旨在提供一个详细的开发步骤和任务分解，以指导项目的顺利进行。

## 0. 项目准备阶段

-   [x] 0.1. 确定项目负责人和团队成员（如果适用）。
-   [x] 0.2. 建立代码仓库 (例如 Git, GitHub/GitLab)。
-   [x] 0.3. 搭建开发、测试和（可选）生产环境的基本框架。
-   [x] 0.4. 详细阅读并理解 <mcfile name="DESIGN.md" path="/Users/yourui/Library/CloudStorage/Dropbox/repo/code-black-sphere/DESIGN.md"></mcfile>。

## 1. 后端开发 (Flask)

### 1.1. 环境搭建与项目初始化

-   [x] 1.1.1. 安装 Python, pip 和 uv
-   [x] 1.1.2. 使用 uv 创建并激活 Python 虚拟环境。
-   [x] 1.1.3. 安装 Flask 及其他必要库 (例如 `flask-sqlalchemy`, `flask-migrate`, `python-dotenv` 等)。
-   [x] 1.1.4. 初始化 Flask 项目结构 (应用工厂模式、蓝图等)。
-   [x] 1.1.5. 配置数据库连接 (SQLite)。

### 1.2. 数据库模型定义与迁移

-   [x] 1.2.1. 根据 <mcfile name="DESIGN.md" path="/Users/yourui/Library/CloudStorage/Dropbox/repo/code-black-sphere/DESIGN.md"></mcfile> 中 4. 数据模型部分，定义 SQLAlchemy 模型：
    -   [x] 1.2.1.1. `candidates` 表模型。
    -   [x] 1.2.1.2. `problems` 表模型。
    -   [x] 1.2.1.3. `test_cases` 表模型。
    -   [x] 1.2.1.4. `submissions` 表模型。
    -   [x] 1.2.1.5. `candidate_problem_tabs` 表模型。
    -   [x] 1.2.1.6. `settings` 表模型。
-   [x] 1.2.2. 初始化数据库迁移工具 (如 Flask-Migrate)。
-   [x] 1.2.3. 生成并应用初始数据库迁移。

### 1.3. API 接口开发 (RESTful)

#### 1.3.1. 候选人管理 API (`/candidates`)

-   [x] 1.3.1.1. `POST /candidates`: 创建新候选人。
-   [x] 1.3.1.2. `GET /candidates`: 获取所有候选人列表。
-   [x] 1.3.1.3. `GET /candidates/<id>`: 获取特定候选人信息 (可选，根据需求)。
-   [x] 1.3.1.4. `PUT /candidates/<id>`: 更新候选人信息 (可选)。
-   [x] 1.3.1.5. `DELETE /candidates/<id>`: 删除候选人 (可选，注意级联删除相关数据)。

#### 1.3.2. 题目管理 API (`/problems`)

-   [x] 1.3.2.1. `POST /problems`: 创建新题目 (包括题目描述、LLM Prompt)。
-   [x] 1.3.2.2. `GET /problems`: 获取所有题目列表 (可包含分页、筛选)。
-   [x] 1.3.2.3. `GET /problems/<id>`: 获取特定题目详情 (包括其所有测试用例)。
-   [x] 1.3.2.4. `PUT /problems/<id>`: 更新题目信息。
-   [x] 1.3.2.5. `DELETE /problems/<id>`: 删除题目 (级联删除关联的测试用例、答题记录等)。

#### 1.3.3. 测试用例管理 API (`/problems/<problem_id>/testcases`)

-   [x] 1.3.3.1. `POST /problems/<problem_id>/testcases`: 为指定题目添加测试用例。
-   [x] 1.3.3.2. `GET /problems/<problem_id>/testcases`: 获取指定题目的所有测试用例。
-   [x] 1.3.3.3. `GET /testcases/<id>`: 获取特定测试用例详情。
-   [x] 1.3.3.4. `PUT /testcases/<id>`: 更新特定测试用例。
-   [x] 1.3.3.5. `DELETE /testcases/<id>`: 删除特定测试用例。

#### 1.3.4. 答题提交与评测 API (`/submissions`)

-   [x] 1.3.4.1. `POST /submissions`: 提交代码进行评测。 (执行和评估已完成)
    -   接收 `candidate_id`, `problem_id`, `language`, `code`。
    -   调用代码执行模块。
    -   保存 `submissions` 记录，包括 `test_results`。
    -   (异步) 调用 LLM API 进行代码评估，更新 `llm_review`。
-   [x] 1.3.4.2. `GET /submissions`: 获取答题记录列表 (可按候选人、题目筛选)。
-   [x] 1.3.4.3. `GET /submissions/<id>`: 获取特定答题记录详情。
-   [x] 1.3.4.4. `GET /submissions/candidate/<candidate_id>/problem/<problem_id>`: 获取特定候选人特定题目的最新或所有提交记录。

#### 1.3.5. Tab 管理 API (`/candidates/<candidate_id>/tabs`)

-   [x] 1.3.5.1. `POST /candidates/<candidate_id>/tabs`: 为候选人添加新的题目 Tab。
    -   接收 `problem_id`。
    -   保存到 `candidate_problem_tabs` 表。
-   [x] 1.3.5.2. `GET /candidates/<candidate_id>/tabs`: 获取候选人当前打开的所有 Tab (problem_id 列表)。
-   [x] 1.3.5.3. `DELETE /candidates/<candidate_id>/tabs/<problem_id>`: 移除候选人的某个 Tab。
-   [x] 1.3.5.4. `PUT /candidates/<candidate_id>/tabs`: 更新候选人 Tab 的顺序 (可选)。

#### 1.3.6. 设置管理 API (`/settings`)

-   [x] 1.3.6.1. `GET /settings`: 获取所有设置项。
-   [x] 1.3.6.2. `GET /settings/<key>`: 获取特定设置项的值。
-   [x] 1.3.6.3. `PUT /settings/<key>`: 更新或创建特定设置项的值 (例如 `deepseek_api_key`, `default_problem_id`)。
    -   API Key 存储前需要加密。

#### 1.3.7. 题目导入/导出 API

-   [x] 1.3.7.1. `POST /problems/import`: 导入题目数据 (JSON 文件)。
    -   处理文件上传。
    -   解析 JSON，根据题目名称判断是新增还是覆盖。
-   [x] 1.3.7.2. `GET /problems/export`: 导出所有题目数据为 JSON 文件。

### 1.4. 代码执行模块

-   [x] 1.4.1. 调研并选择合适的开源判题 Docker 框架 (如 Judge0, Piston API)。
    -   初步调研完成，选择 Judge0 作为判题引擎。
-   [x] 1.4.2. 学习并集成所选框架的 API。
-   [x] 1.4.3. 实现代码执行服务，该服务接收代码、语言、输入，并调用判题框架执行。
    -   [x] 1.4.3.1. 实现与判题引擎的 API 对接，支持 Python, JavaScript, Java, C++。
    -   [x] 1.4.3.2. 安全处理：确保用户提交的代码在沙箱环境中执行，限制 CPU、内存、执行时间。
    -   [x] 1.4.3.3. 结果解析：从判题引擎获取执行结果 (编译错误、运行时错误、答案正确/错误、超时、超内存等)。
-   [x] 1.4.4. 实现测试用例评测逻辑：
    -   [x] 1.4.4.1. 遍历题目的所有测试用例。
    -   [x] 1.4.4.2. 针对每个测试用例执行用户代码。
    -   [x] 1.4.4.3. 比较实际输出与预期输出。
    -   [x] 1.4.4.4. 记录每个测试用例的通过状态、实际输出和错误信息到 `test_results` (JSON 格式)。

### 1.5. LLM 集成模块

-   [x] 1.5.1. 实现与 DeepSeek API (或其他 LLM API) 的交互逻辑。
-   [x] 1.5.2. 从数据库获取 `llm_prompt` 模板。
-   [x] 1.5.3. 根据用户代码和 Prompt 模板构造发送给 LLM 的请求。
-   [x] 1.5.4. 实现流式接收 LLM API 的响应。 (初步实现，待优化)
-   [x] 1.5.5. 将 LLM 返回的点评内容存储到 `submissions` 表的 `llm_review` 字段。
-   [x] 1.5.6. 错误处理。
    -   [x] 1.5.6.1. LLM API 调用超时处理
    -   [x] 1.5.6.2. LLM 响应解析错误处理
    -   [x] 1.5.6.3. LLM 响应内容验证

### 1.6. 后端单元测试与集成测试

-   [ ] 1.6.1. 为各个模块和 API 编写单元测试。
-   [x] 1.6.2. 进行集成测试，确保各组件协同工作正常。

## 2. 前端开发 (React)

### 2.1. 环境搭建与项目初始化

-   [x] 2.1.1. 安装 Node.js 和 npm/yarn。
-   [x] 2.1.2. 使用 `create-react-app` 或 Vite 初始化 React 项目。
-   [x] 2.1.3. 安装必要的依赖库 (例如 `axios` for API calls, `react-router-dom` for routing, state management library like Redux Toolkit or Zustand, UI component library like MUI or Ant Design, Markdown renderer, code editor component)。
-   [x] 2.1.4. 配置项目结构 (组件、页面、服务、工具函数等目录)。

### 2.2. 基础布局与路由

-   [x] 2.2.1. 实现主页面布局：左侧边栏 + 右侧主区域。
-   [x] 2.2.2. 配置前端路由：
    -   [x] 2.2.2.1. 主判题界面 (`/` or `/judge`)
    -   [x] 2.2.2.2. 题目编辑界面 (`/problems/edit/:id` or `/problems/new`)
    -   [x] 2.2.2.3. 设置界面 (`/settings`)

### 2.3. 状态管理

-   [x] 2.3.1. 选择并集成状态管理方案 (如 Redux Toolkit, Zustand, or React Context API)。
-   [x] 2.3.2. 定义全局状态，例如：
    -   当前选中的候选人。
    -   候选人列表。
    -   题目列表。
    -   当前打开的题目 Tabs 及其状态 (代码、滚动位置等)。
    -   API 加载状态和错误信息。

### 2.4. UI 组件开发

#### 2.4.1. 候选人管理组件

-   [x] 2.4.1.1. 候选人列表展示组件 (左侧边栏)。
-   [x] 2.4.1.2. 新建候选人按钮及输入框/弹窗组件。
-   [x] 2.4.1.3. 候选人切换逻辑，更新全局状态和右侧 Tab 内容。

#### 2.4.2. 判题界面 (Tabs) 组件

-   [x] 2.4.2.1. Tab 容器组件，管理多个题目 Tab。
-   [x] 2.4.2.2. 单个 Tab 组件：
    -   显示题目名称。
    -   关闭 Tab 按钮 (仅当 Tab 数量 > 1)。
-   [x] 2.4.2.3. "新建 Tab" 按钮及题目选择逻辑。
-   [x] 2.4.2.4. Tab 状态保持逻辑 (CSS 显示/隐藏，不销毁 DOM)。
-   [x] 2.4.2.5. 默认 Tab 加载逻辑。
-   [x] 2.4.2.6. 将现有 `SubmissionForm.jsx` 的功能 (代码编辑、提交、基本结果展示) 重构并集成到单个 Tab 内容中，使其与题目描述、详细测试用例、LLM 点评等组件协同工作。
    -   [x] 2.4.2.6.1. 调整 Candidate ID 和 Problem ID 的获取方式，以适应全局候选人选择和 Tab 切换逻辑。

#### 2.4.3. 题目 Tab 内容组件

-   [x] 2.4.3.1. **题目描述组件**: 
    -   可展开/收起。
    -   Markdown 内容渲染 (使用 `react-markdown` 或类似库)。
-   [x] 2.4.3.2. **答题代码区组件**:
    -   [x] 集成代码编辑器 (Monaco Editor, CodeMirror, or react-simple-code-editor with Prism.js for highlighting)。
    -   [x] 支持语言选择下拉菜单。
    -   [x] 代码输入和编辑功能。
    -   [x] "运行测试并评估"按钮。
-   [x] 2.4.3.3. **测试用例及运行结果组件**: 
    -   列表形式展示测试用例。
    -   每项测试用例显示：输入参数、预期输出。
    -   动态显示运行状态 (通过/失败)、实际输出、错误信息。
-   [x] 2.4.3.4. **大模型点评组件**: 
    -   显示 LLM 返回的评估、建议和分数。
    -   实现流式显示效果 (如果后端支持 SSE 或 WebSocket)。

#### 2.4.4. 题目编辑界面组件

-   [ ] 2.4.4.1. 题目基本信息编辑组件
    -   [ ] 2.4.4.1.1. 题目名称输入框
    -   [ ] 2.4.4.1.2. 题目难度选择
    -   [ ] 2.4.4.1.3. 题目分类标签
-   [ ] 2.4.4.2. 题目描述 Markdown 编辑器组件
    -   [ ] 2.4.4.2.1. Markdown 编辑器集成
    -   [ ] 2.4.4.2.2. 实时预览功能
    -   [ ] 2.4.4.2.3. 图片上传功能
-   [ ] 2.4.4.3. 测试用例管理组件
    -   [ ] 2.4.4.3.1. 测试用例列表展示
    -   [ ] 2.4.4.3.2. 测试用例添加/编辑/删除
    -   [ ] 2.4.4.3.3. 测试用例导入/导出
-   [ ] 2.4.4.4. LLM Prompt 编辑组件
    -   [ ] 2.4.4.4.1. Prompt 模板编辑器
    -   [ ] 2.4.4.4.2. 变量替换预览
    -   [ ] 2.4.4.4.3. Prompt 测试功能
-   [ ] 2.4.4.5. 题目预览组件
    -   [ ] 2.4.4.5.1. 完整题目预览
    -   [ ] 2.4.4.5.2. 测试用例预览
    -   [ ] 2.4.4.5.3. 代码编辑器预览
-   [ ] 2.4.4.6. 保存和验证逻辑
    -   [ ] 2.4.4.6.1. 表单验证
    -   [ ] 2.4.4.6.2. 自动保存
    -   [ ] 2.4.4.6.3. 版本控制

#### 2.4.5. 设置界面组件

-   [ ] 2.4.5.1. **默认题目设置组件**: 下拉选择或输入框。
-   [ ] 2.4.5.2. **题目管理列表组件**: 
    -   显示所有题目。
    -   新建题目按钮 (导航到题目编辑页)。
    -   编辑题目按钮 (导航到题目编辑页)。
    -   删除题目按钮 (带确认)。
-   [ ] 2.4.5.3. **题目导入/导出组件**: 
    -   导出按钮 (调用 API 下载 JSON)。
    -   导入按钮 (文件选择框，调用 API 上传 JSON，带确认)。
-   [ ] 2.4.5.4. **API Key 管理组件**: 
    -   输入框输入 DeepSeek API Key。
    -   保存按钮 (调用 API 保存)。

### 2.5. API 服务集成

-   [x] 2.5.1. 创建 API 服务模块 (使用 `axios` 或 `fetch`)，封装所有后端 API 调用。
-   [x] 2.5.2. 在各组件中调用 API 服务获取和提交数据。
-   [x] 2.5.3. 处理 API 请求的加载状态和错误显示。

### 2.6. 前端单元测试与组件测试

-   [ ] 2.6.1. 使用 Jest 和 React Testing Library 为关键组件和工具函数编写测试。
-   [ ] 2.6.2. 端到端测试
    -   [ ] 2.6.2.1. 用户流程测试
    -   [ ] 2.6.2.2. 跨组件交互测试
    -   [ ] 2.6.2.3. 数据流测试

## 3. 核心功能端到端实现

此阶段关注将前后端功能串联起来，形成完整用户流程。

-   [x] 3.1. **候选人管理流程**: 
    -   [x] 3.1.1. 创建新候选人并显示在列表。
    -   [x] 3.1.2. 切换候选人，正确加载其对应的 Tab 和 Tab 内状态。
-   [x] 3.2. **题目浏览与答题流程**: 
    -   [x] 3.2.1. 用户选择题目，打开新的 Tab。
    -   [x] 3.2.2. Tab 内正确显示题目描述。
    -   [x] 3.2.3. 用户在代码区输入代码，选择语言。
    -   [x] 3.2.4. 点击"运行测试并评估"：
        -   [x] 3.2.4.1. 前端发送代码到后端。
        -   [x] 3.2.4.2. 后端执行代码并通过所有测试用例。
        -   [x] 3.2.4.3. 前端展示每个测试用例的通过状态、实际输出/错误。
        -   [x] 3.2.4.4. 后端调用 LLM API 进行评估。
        -   [x] 3.2.4.5. 前端流式展示 LLM 点评内容。
-   [ ] 3.3. **题目编辑流程**: 
    -   [ ] 3.3.1. 题目创建流程
        -   [ ] 3.3.1.1. 基本信息填写
        -   [ ] 3.3.1.2. 测试用例创建
        -   [ ] 3.3.1.3. Prompt 配置
        -   [ ] 3.3.1.4. 保存到数据库
    -   [ ] 3.3.2. 题目编辑流程
        -   [ ] 3.3.2.1 从设置界面或判题 Tab 进入题目编辑界面。
        -   [ ] 3.3.2.2. 信息更新
        -   [ ] 3.3.2.3. 测试用例修改
        -   [ ] 3.3.2.4. 保存到数据库
    -   [ ] 3.3.3. 题目删除流程
        -   [ ] 3.3.3.1. 删除确认
        -   [ ] 3.3.3.2. 关联数据处理
    -   [ ] 3.3.4. 题目导入/导出流程
        -   [ ] 3.3.4.1. JSON 格式支持
        -   [ ] 3.3.4.2. 批量导入
        -   [ ] 3.3.4.3. 导出模板
    -   [ ] 3.3.5. 题目预览流程
        -   [ ] 3.3.5.1. 实时预览
        -   [ ] 3.3.5.2. 测试运行
        -   [ ] 3.3.5.3. 效果验证
-   [ ] 3.4. **设置管理流程**: 
    -   [ ] 3.4.1. 设置默认题目并生效。
    -   [ ] 3.4.2. 导入/导出题目功能测试。
    -   [ ] 3.4.3. API Key 设置与保存 (加密验证)。
-   [ ] 3.5. **Tab 状态保持与恢复**: 
    -   [ ] 3.5.1. 切换 Tab 或候选人时，代码、滚动位置等状态被保留。
    -   [ ] 3.5.2. 关闭应用再打开（或刷新页面），用户上次打开的 Tabs 和候选人被恢复。

## 4. 集成与测试

-   [x] 4.1. **前后端集成测试**: 确保所有 API 接口按预期工作，数据流正确。

## 5. 部署

-   [ ] 5.1. **后端部署**: 
    -   [ ] 5.1.1. 开发环境配置
        -   [ ] 5.1.1.1. 环境变量设置
        -   [ ] 5.1.1.2. 依赖管理
        -   [ ] 5.1.1.3. 日志配置

## 6. 文档与维护

-   [ ] 6.1. **用户手册**: 编写简单的用户指南。
-   [ ] 6.2. **开发者文档**: 
    -   [ ] 6.2.1. 完善 API 文档 (可使用 Swagger/OpenAPI)。
    -   [ ] 6.2.2. 更新代码注释和项目结构说明。

---

**注意**: 
- 本计划为初步规划，具体任务和优先级可能根据实际开发情况进行调整。
- 每个任务前的 `[ ]` 可用于标记完成状态 (例如 `[x]` 表示已完成)。
- 建议定期回顾和更新此开发计划。
